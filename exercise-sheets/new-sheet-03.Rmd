---
title: "Homework Sheet 3 -- Comparison testing"
date: 'Due: Thursday, December 22 by 23:59 CET'
author: ""
output: 
  html_document:
    toc: true
    toc_depth: 2
    highlight: tango
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, error = F, message = F, warning = F)

```

```{r libraries, include=FALSE, message=FALSE, warning=FALSE}

# package for convenience functions (e.g. ggplot2, dplyr, etc.)
library(tidyverse)

# use the minimal theme for plotting
ggplot2::theme_set(ggplot2::theme_minimal())

# global color scheme / non-optimized
project_colors = c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#000000")

# setting theme colors globally
scale_colour_discrete <- function(...) {
  scale_colour_manual(..., values = project_colors)
}
scale_fill_discrete <- function(...) {
   scale_fill_manual(..., values = project_colors)
} 

# nicer global knitr options
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
                      cache = FALSE, fig.align = 'center')


```

# Instructions

* Create an Rmd file with the names of your group members in the 'author' heading and answer the following questions.
* When all answers are ready, 'Knit' the document to produce a HTML file.
* Create a ZIP archive called "IDA_HW03-names.zip" (where %names% are the last names of all members in the group as written in the 'author' field) containing:
   * an R Markdown file "IDA_HW03-names.Rmd"
   * a knitted HTML document "IDA_HW03-names.html"
   * any other files necessary to compile your Rmarkdown to HTML (data, pictures etc.)
* Upload the ZIP archive on Stud.IP in your group folder before the deadline (see above). You may upload as many times as you like before the deadline, only your final submission will count.

# <span style = "color:firebrick">Exercise 1:</span> Inspect, preprocess & plot the data [15 points]

## Ex 1.a Load and inspect the data [1 point]

In this exercise sheet, we will look at the data from the British Lexicon Project (Keuleers et al. 2012). `blp.csv` is a subset of the full BLP data set, which contains reaction times and responses from 40,626 trials of a lexical decision experiment. The experimental items include both words and non-words. The column `CELEX_frequency` contains raw frequency of each word in the CELEX database (Baayen et al. 1995). Load the data into R and display the first five rows of the data set.

**Solution:** 

```{r}
blp <- read_csv("blp.csv")
head(blp, 5)
```

## Ex 1.b Determine the number of words and non-words [1 point]

Use R to extract the number of unique words and non-words that were presented to participants in this data set.

**Solution:**

```{r, message = T}
message("There are ", blp |> filter(lexicality == "W") |> 
          pull(spelling) |> unique() |>  length(),
        " unique words and ", blp |> filter(lexicality == "N") |>
          pull(spelling) |> unique() |>  length(), " unique non-words.")
```


## Ex 1.c Identify variables of interest [2 points]

<!-- one point for dependent; one for independent -->

We are interested in whether reaction times to words are faster than reaction times to non-words. Looking at the data you have loaded in R, which columns in the data frame represent the main independent and dependent variables of interest?

**Solution:**

```{r}
# independent: `lexicality`
# dependent: `rt`
```

## Ex 1.d By-word mean RT [2 points]

<!-- one point for correct tibble; one point for correct plot -->

Create a tibble in which each row shows the mean reaction time for a different word or non-word. This tibble will have as many rows as there are words and non-words in the data set. (**Hint:** Use `group_by` and `summarize`.)

Create a histogram using different colours for words and non-words, and showing the mean reaction time on the $x$-axis. Reaction times usually have a long right tail, and log-transforming the values before calculating the mean may help make the difference between words and non-words more obvious.

**Solution:**

```{r}
blp |>
  group_by(spelling, lexicality) |>
  summarize(
    mean_RT = mean(log(rt), na.rm = T)
  ) |> ungroup() |> 
  ggplot(aes(x = mean_RT,
             fill = lexicality,
             color = lexicality)) +
  geom_histogram(alpha = .65) +
  labs(
    x = "Mean log RT",
    y = "Count",
    color = "Word or non-word?",
    fill = "Word or non-word?"
  )
```

## Ex 1.e Remove individual trials [2 points]

<!-- one point for correct exclusion; one point for correct output of number of exclusions -->

Exclude all trials with reaction times shorter than 100 ms.
Use R to output information about how many trials have been excluded in this way.

**Solution:**

```{r, message = T}
blp <- blp  |> 
  mutate(outlier_trial = case_when(rt < 100 ~ TRUE,
                                   TRUE ~ FALSE))
message(sum(blp$outlier_trial), " trial(s) were excluded based on suspicious reaction times.")
blp <- filter(blp, outlier_trial == FALSE)
```

## Ex 1.f Remove outlier trials [5 points]

<!-- four points for correct exclusion; one point for correct output of number of exclusions -->

We will determine which trials are considered outliers on a per-participant basis. For every participant, calculate mean and standard deviation of their reaction time per condition (word or non-word).  We will define outliers as reactions times that more than two standard deviations away from the mean of experimental condition. Remove outlier trials, and save the cleaned dataset. (**Hint:** You can adapt code from [this section of the web-book](https://michael-franke.github.io/intro-data-analysis/app-93-data-sets-mental-chronometry.html#cleaning-by-participant-1).)

Use R to output information about how many trials have been excluded in this way.

**Solution:**

```{r, message = T}
blp <- blp  |> 
  group_by(participant, lexicality) |> 
  mutate(mean_rt = mean(rt),
         sd_rt = sd(rt)) |>
  ungroup() |> 
  mutate(outlier_trial = case_when(abs(rt - mean_rt) > 2 * sd_rt ~ TRUE,
                                   TRUE ~ FALSE))

message(sum(blp$outlier_trial), " trial(s) were excluded as outliers.")
blp <- filter(blp, outlier_trial == FALSE)
```


## Ex 1.g Show summary statistics [2 points]

<!-- one point for correct tibble; one point for correct answer about the hypothesis -->

Produce a tibble which shows the mean of all reaction times aggregated over individual participants and items for the two experimental conditions (word and non-word).

Based on these summary statistics, would you conclude that reaction times to words are faster than to non-words?

**Solution:**

```{r}
blp |>  group_by(lexicality)  |> 
  summarise(
    mean_RT = mean(rt, na.rm = T)
  )
```

```{r}
# On average, reaction times to non-words appear to be slower than to words.
```


# <span style = "color:firebrick">Exercise 2:</span> Test the hypothesis [20 points]

We want to know whether in the `blp` data, reaction times to words are faster than reaction times to non-words.

## Ex 2.a Formulate $H_0$ and $H_1$ [1 point]

Formulate the null hypothesis $H_0$ and the alternative hypothesis $H_1$. 

**Solution**

> **Null hypothesis:** Mean reaction time to non-words is the same as to words.
> 
> **Alternative hypothesis:** Mean reaction time to words is smaller than mean reaction time to non-words.
> 
> If we let $\mu_1$ denote the true mean reaction time to words, and $\mu_2$ the true mean reaction time to non-words, we would express the null and alternative hypotheses formally as follows:
$$ H_0: \quad \mu_1 = \mu_2 \\
H_1: \quad \mu_1 < \mu_2  $$


## Ex 2.b Plot the reaction times distributions for words and non-words [2 points]

Create a density plot of reaction times to words and non-words (use different colours to distinguish words from non-words).

**Solution:**

```{r}
blp |> 
  ggplot(aes(x = rt, color = lexicality, fill = lexicality)) +
  geom_density(alpha = .5) +
  labs(
    x = "Reaction time (ms)",
    y = "Density",
    colour = "Word or non-word?",
    fill = "Word or non-word?"
  )
```


## Ex 2.c Check if assumptions for the t-test are fulfilled [7 points]

Mention the assumptions that have to be fulfilled if we want to do a t-test to compare mean reaction times to words vs. non-words in the `blp` dataset. Check if they are fulfilled.

What kind of t-test is appropriate for this dataset (i.e. one-sample, two-sample, ...)? Explain your choice. If you think that some preprocessing is needed before doing a t-test, preprocess the data.

**Solution:**

> We want to check two assumptions: that the data are normally distributed, and that observations are independent.
>
> We have seen in the density plot above that reaction times are not normally distributed, but rather there is a long right tail.
> (Alternatively, we could have done this check with a Q-Q plot as shown below.)

```{r}
qqnorm(blp$rt)
qqline(blp$rt)
```

> We can log-transform the reaction times so that the data are better approximated by the normal distribution.
>
> Additionally, we have repeated measures (multiple responses from the same participants making decisions about the same set of words and non-words). We will aggregate the data over items, so that there is just a single value (mean log RT) per participant per condition (word or non-word).

```{r}
by_participant <- blp |> 
  group_by(participant, lexicality) |> 
  summarize(mean_logRT = mean(log(rt))) |> 
  ungroup() |> 
  pivot_wider(names_from = lexicality,
              values_from = mean_logRT)

head(by_participant)
```

> Each row of the data frame now represents the data of just one participant. We can now run a paired $t$-test to check the pairwise differences between reaction times to words vs. non-words.

## Ex 2.d Run the t-test and report the results [10 points]

Run the appropriate t-test in R, and describe your results verbally.

**Solution:**

```{r}
t.test(by_participant$W, by_participant$N,
       alternative = "less",
       paired = TRUE)
```
> The results of the paired $t$-test show that responses to words are faster than responses to non-words, and this difference is significant.

**References**

- Keuleers, E., Lacey, P., Rastle, K. The British Lexicon Project: Lexical decision data for 28,730 monosyllabic and disyllabic English words. Behav Res 44, 287–304 (2012). <https://doi.org/10.3758/s13428-011-0118-4>
- Baayen, R. H., Piepenbrock, R., & Gulikers, H. (1995). The CELEX Lexical Database. Philadelphia, PA: Linguistic Data Consortium.
